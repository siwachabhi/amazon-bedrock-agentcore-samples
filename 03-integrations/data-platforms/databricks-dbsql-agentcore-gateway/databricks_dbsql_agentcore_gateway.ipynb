{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-001",
   "metadata": {},
   "source": [
    "# Databricks SQL MCP Server with Amazon Bedrock AgentCore Gateway\n",
    "\n",
    "This notebook demonstrates how to connect a [Databricks SQL (DBSQL) MCP server](https://docs.databricks.com/en/generative-ai/mcp/managed-mcp.html) to [Amazon Bedrock AgentCore Gateway](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/gateway.html). AgentCore Gateway manages both inbound authentication (via Amazon Cognito) and outbound authentication (via Databricks OAuth2 M2M), so you don't need to write any custom auth code.\n",
    "\n",
    "![Databricks SQL MCP Server with Amazon Bedrock AgentCore Gateway Architecture](images/architecture.png)\n",
    "\n",
    "\n",
    "By the end of this notebook you will have:\n",
    "1. Configured Databricks credentials for machine-to-machine (M2M) OAuth\n",
    "2. Created (or reused) an AgentCore Gateway with Cognito-based inbound auth\n",
    "3. Set up an OAuth2 credential provider for outbound Databricks auth via AgentCore Identity\n",
    "4. Added the Databricks DBSQL MCP server as a gateway target\n",
    "5. Tested the gateway locally with a Strands Agent\n",
    "6. Deployed the agent to AgentCore Runtime for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview-databricks",
   "metadata": {},
   "source": [
    "## Databricks Managed MCP Servers Overview\n",
    "\n",
    "Databricks provides [managed MCP servers](https://docs.databricks.com/en/generative-ai/mcp/managed-mcp.html) that expose platform capabilities — such as SQL querying, Unity Catalog, vector search, and Genie spaces — as MCP-compatible tools. These servers follow the Streamable HTTP transport and are hosted at endpoints like:\n",
    "\n",
    "- `https://<workspace-host>/api/2.0/mcp/sql` — Run SQL queries against Unity Catalog tables\n",
    "- `https://<workspace-host>/api/2.0/mcp/functions/<catalog>/<schema>` — Invoke Unity Catalog functions\n",
    "- `https://<workspace-host>/api/2.0/mcp/vector-search/<catalog>/<schema>` — Query vector search indexes\n",
    "- `https://<workspace-host>/api/2.0/mcp/genie/<genie_space_id>` — Interact with Genie spaces\n",
    "\n",
    "In this notebook we use the **SQL MCP server** (`/api/2.0/mcp/sql`), which lets agents run SQL queries against any table the authenticated principal has access to in Unity Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview-gateway",
   "metadata": {},
   "source": [
    "## Amazon Bedrock AgentCore Gateway Overview\n",
    "\n",
    "Amazon Bedrock AgentCore Gateway turns existing APIs and services into fully-managed MCP servers without needing to manage infrastructure or hosting. Gateway employs a dual authentication model:\n",
    "\n",
    "- **Inbound Auth** — Validates and authorizes users attempting to access gateway targets (e.g., Cognito, Custom JWT)\n",
    "- **Outbound Auth** — Enables the gateway to securely connect to backend resources on behalf of authenticated users (e.g., OAuth2 M2M via AgentCore Identity)\n",
    "\n",
    "More details:\n",
    "- [AgentCore Gateway documentation](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/gateway.html)\n",
    "- [AgentCore Gateway tutorials](https://github.com/awslabs/amazon-bedrock-agentcore-samples/tree/main/01-tutorials/02-AgentCore-gateway)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. **AWS credentials** configured (`aws configure`) with permissions to create AgentCore resources, IAM roles, and Cognito user pools\n",
    "2. **Databricks workspace** with Unity Catalog enabled\n",
    "3. **Databricks service principal** with an OAuth secret (see [Setting up Databricks credentials](#setting-up-databricks-credentials) below)\n",
    "4. **Python 3.10+**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3 bedrock-agentcore bedrock-agentcore-starter-toolkit strands-agents strands-agents-tools mcp --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "databricks-credentials",
   "metadata": {},
   "source": [
    "## Setting up Databricks Credentials\n",
    "\n",
    "To authenticate AgentCore Gateway with your Databricks workspace, you need a **service principal** with an OAuth secret. This enables machine-to-machine (M2M) authentication using the OAuth2 client credentials flow.\n",
    "\n",
    "### Step 1: Create a Service Principal\n",
    "\n",
    "1. In your Databricks workspace, go to **Settings** → **Identity and access** → **Service principals**\n",
    "\n",
    "![Databricks Settings page showing the Service principals section](images/databricks_1.png)\n",
    "\n",
    "2. Click **Add service principal** and provide a name (e.g., `agentcore-gateway`)\n",
    "\n",
    "![Databricks Settings page showing the Service principals section](images/databricks_2.png)\n",
    "\n",
    "3. After creation, note the **Application ID** — this is your `client_id`\n",
    "\n",
    "### Step 2: Generate an OAuth Secret\n",
    "\n",
    "1. Select the service principal you just created\n",
    "2. Go to the **Secrets** tab and click **Generate secret**\n",
    "3. Copy the **Secret** value immediately — it will not be shown again. This is your `client_secret`\n",
    "\n",
    "### Step 3: Grant Permissions\n",
    "\n",
    "Ensure the service principal has access to the Unity Catalog tables you want to query:\n",
    "\n",
    "1. Go to **Catalog** → select your catalog/schema → **Permissions**\n",
    "2. Grant `USE CATALOG`, `USE SCHEMA`, and `SELECT` permissions to the service principal\n",
    "\n",
    "For more details, see the [Databricks OAuth M2M authentication documentation](https://docs.databricks.com/en/dev-tools/auth/oauth-m2m.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "databricks-mcp-docs",
   "metadata": {},
   "source": [
    "### Databricks Managed MCP Server Configuration\n",
    "\n",
    "Databricks managed MCP servers are available out of the box — no additional setup is required beyond authentication. The SQL MCP server endpoint is:\n",
    "\n",
    "```\n",
    "https://<your-workspace-host>/api/2.0/mcp/sql\n",
    "```\n",
    "\n",
    "For a full list of available managed MCP servers and configuration options, see the [Databricks managed MCP documentation](https://docs.databricks.com/en/generative-ai/mcp/managed-mcp.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Step 1: Configure Your Environment\n",
    "\n",
    "Set your Databricks workspace host and service principal credentials. Replace the placeholder values below with your actual credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Databricks workspace URL (e.g., https://dbc-xxxxxxxx-xxxx.cloud.databricks.com)\n",
    "DATABRICKS_HOST = \"\"\n",
    "\n",
    "# Service principal credentials from the steps above\n",
    "DATABRICKS_CLIENT_ID = \"\"      # Application ID of the service principal\n",
    "DATABRICKS_CLIENT_SECRET = \"\"   # OAuth secret you generated\n",
    "\n",
    "# AWS region for AgentCore resources\n",
    "REGION = \"us-east-1\"\n",
    "\n",
    "assert DATABRICKS_HOST != \"https://REPLACE_ME.cloud.databricks.com\", \"Please set your Databricks workspace host\"\n",
    "assert DATABRICKS_CLIENT_ID != \"REPLACE_ME\", \"Please set your Databricks client ID\"\n",
    "assert DATABRICKS_CLIENT_SECRET != \"REPLACE_ME\", \"Please set your Databricks client secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient\n",
    "\n",
    "boto_session = Session()\n",
    "sts = boto3.client('sts')\n",
    "account_id = sts.get_caller_identity().get('Account')\n",
    "agentcore = boto3.client('bedrock-agentcore-control', region_name=REGION)\n",
    "\n",
    "print(f\"AWS Account: {account_id}\")\n",
    "print(f\"Region: {REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "## Step 2: Create or Reuse an AgentCore Gateway\n",
    "\n",
    "You have two options:\n",
    "- **Option A**: Create a new gateway from scratch (run the cells in this section)\n",
    "- **Option B**: Reuse an existing gateway by loading its configuration from `gateway_config.json`\n",
    "\n",
    "If you already have a gateway deployed (e.g., from a previous run or from the standalone `setup.py` script), skip to **Option B** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2a-header",
   "metadata": {},
   "source": [
    "### Option A: Create a New Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = GatewayClient(region_name=REGION)\n",
    "client.logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create Cognito authorizer for inbound authentication\n",
    "print(\"Creating Cognito authorizer (inbound auth)...\")\n",
    "cognito = client.create_oauth_authorizer_with_cognito(\"DatabricksGateway\")\n",
    "\n",
    "# Create the MCP gateway\n",
    "print(\"Creating Gateway...\")\n",
    "gateway = client.create_mcp_gateway(\n",
    "    name=\"DatabricksGateway\",\n",
    "    role_arn=None,\n",
    "    authorizer_config=cognito[\"authorizer_config\"],\n",
    "    enable_semantic_search=True,\n",
    ")\n",
    "client.fix_iam_permissions(gateway)\n",
    "\n",
    "gateway_url = gateway[\"gatewayUrl\"]\n",
    "gateway_id = gateway[\"gatewayId\"]\n",
    "\n",
    "print(f\"Gateway URL: {gateway_url}\")\n",
    "print(f\"Gateway ID: {gateway_id}\")\n",
    "print(\"Waiting 30s for IAM propagation...\")\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "screenshot-gateway",
   "metadata": {},
   "source": [
    "![AgentCore console showing the newly created DatabricksGateway](images/AgentCoreGW_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "#### Create Databricks OAuth2 Credential Provider (Outbound Auth)\n",
    "\n",
    "AgentCore Identity manages the outbound OAuth2 credentials so the gateway can authenticate with Databricks on behalf of your agent. We create a credential provider that stores the service principal's client ID and secret, and uses the Databricks OIDC token endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-cred-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = DATABRICKS_HOST.rstrip('/')\n",
    "token_endpoint = f\"{host}/oidc/v1/token\"\n",
    "\n",
    "print(\"Creating Databricks OAuth2 credential provider...\")\n",
    "cred_provider = agentcore.create_oauth2_credential_provider(\n",
    "    name=\"databricks-dbsql-oauth\",\n",
    "    credentialProviderVendor=\"CustomOauth2\",\n",
    "    oauth2ProviderConfigInput={\n",
    "        \"customOauth2ProviderConfig\": {\n",
    "            \"oauthDiscovery\": {\n",
    "                \"authorizationServerMetadata\": {\n",
    "                    \"issuer\": host,\n",
    "                    \"tokenEndpoint\": token_endpoint,\n",
    "                    \"authorizationEndpoint\": token_endpoint,\n",
    "                }\n",
    "            },\n",
    "            \"clientId\": DATABRICKS_CLIENT_ID,\n",
    "            \"clientSecret\": DATABRICKS_CLIENT_SECRET,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "provider_arn = cred_provider[\"credentialProviderArn\"]\n",
    "secret_arn = cred_provider.get('secretArn') or cred_provider.get('clientSecretArn', {}).get('secretArn', '')\n",
    "print(f\"Credential provider ARN: {provider_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "#### Update Gateway Role Permissions\n",
    "\n",
    "The gateway's IAM role needs permissions to fetch workload access tokens, retrieve OAuth2 tokens from the credential provider, and read the stored secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "update-iam",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Updating gateway role permissions...\")\n",
    "gateway_details = agentcore.get_gateway(gatewayIdentifier=gateway_id)\n",
    "role_arn = gateway_details[\"roleArn\"]\n",
    "role_name = role_arn.split('/')[-1]\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "policy_doc = json.dumps({\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"bedrock-agentcore:GetWorkloadAccessToken\",\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:bedrock-agentcore:{REGION}:*:workload-identity-directory/default\",\n",
    "                f\"arn:aws:bedrock-agentcore:{REGION}:*:workload-identity-directory/default/workload-identity/DatabricksGateway-*\",\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"bedrock-agentcore:GetResourceOauth2Token\",\n",
    "            \"Resource\": provider_arn,\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"secretsmanager:GetSecretValue\",\n",
    "            \"Resource\": secret_arn,\n",
    "        },\n",
    "    ],\n",
    "})\n",
    "\n",
    "iam.put_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyName=\"DatabricksOAuthAccess\",\n",
    "    PolicyDocument=policy_doc,\n",
    ")\n",
    "print(f\"Updated role: {role_name}\")\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-header",
   "metadata": {},
   "source": [
    "#### Add Databricks DBSQL MCP Server as Gateway Target\n",
    "\n",
    "Now we register the Databricks SQL MCP server as a target on the gateway. The gateway will use the OAuth2 credential provider we created to authenticate outbound requests to Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_url = f\"{host}/api/2.0/mcp/sql\"\n",
    "\n",
    "print(f\"Adding Databricks DBSQL MCP server target: {mcp_url}\")\n",
    "target = agentcore.create_gateway_target(\n",
    "    gatewayIdentifier=gateway_id,\n",
    "    name=\"DatabricksDBSQL\",\n",
    "    description=\"Databricks SQL MCP server - run SQL queries against Unity Catalog\",\n",
    "    targetConfiguration={\n",
    "        \"mcp\": {\n",
    "            \"mcpServer\": {\n",
    "                \"endpoint\": mcp_url,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    credentialProviderConfigurations=[\n",
    "        {\n",
    "            \"credentialProviderType\": \"OAUTH\",\n",
    "            \"credentialProvider\": {\n",
    "                \"oauthCredentialProvider\": {\n",
    "                    \"providerArn\": provider_arn,\n",
    "                    \"grantType\": \"CLIENT_CREDENTIALS\",\n",
    "                    \"scopes\": [\"all-apis\"],\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "target_id = target[\"targetId\"]\n",
    "print(f\"Target ID: {target_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sync-tools",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the target to become ready\n",
    "print(\"Waiting for target to be ready...\")\n",
    "for _ in range(24):\n",
    "    t = agentcore.get_gateway_target(gatewayIdentifier=gateway_id, targetId=target_id)\n",
    "    if t.get('status') not in ('Creating', 'Updating'):\n",
    "        break\n",
    "    time.sleep(5)\n",
    "print(f\"Target status: {t.get('status')}\")\n",
    "\n",
    "# Synchronize tools from the Databricks MCP server\n",
    "print(\"Synchronizing tools from Databricks...\")\n",
    "agentcore.synchronize_gateway_targets(\n",
    "    gatewayIdentifier=gateway_id,\n",
    "    targetIdList=[target_id],\n",
    ")\n",
    "print(\"Tools synchronized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-config-header",
   "metadata": {},
   "source": [
    "#### Save Configuration\n",
    "\n",
    "Save the gateway configuration to a JSON file. This file is used by both the local test agent and the AgentCore Runtime deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"gateway_url\": gateway_url,\n",
    "    \"gateway_id\": gateway_id,\n",
    "    \"target_id\": target_id,\n",
    "    \"region\": REGION,\n",
    "    \"client_info\": cognito[\"client_info\"],\n",
    "    \"databricks_host\": host,\n",
    "}\n",
    "\n",
    "with open('gateway_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"Configuration saved to gateway_config.json\")\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2b-header",
   "metadata": {},
   "source": [
    "### Option B: Reuse an Existing Gateway\n",
    "\n",
    "If you already have a gateway deployed, load the configuration from `gateway_config.json`. This file is produced by either Option A above or the standalone `setup.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing gateway configuration\n",
    "with open('gateway_config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "gateway_url = config[\"gateway_url\"]\n",
    "gateway_id = config[\"gateway_id\"]\n",
    "target_id = config[\"target_id\"]\n",
    "REGION = config[\"region\"]\n",
    "host = config[\"databricks_host\"]\n",
    "\n",
    "client = GatewayClient(region_name=REGION)\n",
    "agentcore = boto3.client('bedrock-agentcore-control', region_name=REGION)\n",
    "\n",
    "print(f\"Loaded existing gateway: {gateway_id}\")\n",
    "print(f\"Gateway URL: {gateway_url}\")\n",
    "print(f\"Databricks host: {host}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Test the Gateway Locally with a Strands Agent\n",
    "\n",
    "Before deploying to AgentCore Runtime, let's verify the gateway works by running a Strands Agent locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "token-header",
   "metadata": {},
   "source": [
    "### Get an Access Token\n",
    "\n",
    "Obtain a Cognito access token to authenticate with the gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = client.get_access_token_for_cognito(config['client_info'])\n",
    "print(\"Access token obtained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "list-tools-header",
   "metadata": {},
   "source": [
    "### Connect MCP Client and List Available Tools\n",
    "\n",
    "Create an MCP client pointing at the gateway URL and list the tools synchronized from the Databricks DBSQL MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-tools",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from strands.tools.mcp import MCPClient\n",
    "\n",
    "mcp_client = MCPClient(\n",
    "    lambda: streamablehttp_client(\n",
    "        gateway_url,\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "mcp_client.start()\n",
    "tools = mcp_client.list_tools_sync()\n",
    "print(f\"Available tools: {[t.tool_name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-header",
   "metadata": {},
   "source": [
    "### Create and Run the Agent Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "agent = Agent(\n",
    "    model=BedrockModel(model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\"),\n",
    "    tools=tools,\n",
    "    system_prompt=\"You query Databricks SQL via Unity Catalog. Be concise and return results in a readable format.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-header",
   "metadata": {},
   "source": [
    "### Run a Sample Query\n",
    "\n",
    "Try asking the agent to list available catalogs or query a table. Adjust the prompt below to match your Unity Catalog setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-query",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent(\"List all available catalogs in this Databricks workspace.\")\n",
    "print(f\"\\nAgent: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-query-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a more specific query — adjust to match your tables\n",
    "response = agent(\"Show me the first 5 rows from the default catalog.\")\n",
    "print(f\"\\nAgent: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stop-mcp",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_client.stop()\n",
    "print(\"MCP client stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "runtime-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Deploy the Agent to AgentCore Runtime\n",
    "\n",
    "Now that we've verified the gateway works locally, let's deploy the Strands Agent to [Amazon Bedrock AgentCore Runtime](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/runtime.html) for production use. AgentCore Runtime provides a secure, serverless environment with automatic scaling and session management.\n",
    "\n",
    "The deployment uses the AgentCore Runtime SDK (`bedrock-agentcore`) to wrap our agent as an HTTP service, and the starter toolkit CLI (`agentcore`) to build, containerize, and deploy it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "runtime-agent-header",
   "metadata": {},
   "source": [
    "### Create the Agent Entrypoint\n",
    "\n",
    "We write a `databricks_agent.py` file that:\n",
    "1. Loads the gateway configuration\n",
    "2. Obtains a Cognito access token\n",
    "3. Connects to the gateway via MCP\n",
    "4. Creates a Strands Agent with the gateway tools\n",
    "5. Exposes it as an AgentCore Runtime entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-agent-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile databricks_agent.py\n",
    "\"\"\"\n",
    "Strands Agent deployed on AgentCore Runtime that queries Databricks SQL\n",
    "through AgentCore Gateway.\n",
    "\n",
    "The gateway handles all auth complexity:\n",
    "  - Inbound: Cognito JWT validates agent requests\n",
    "  - Outbound: OAuth2 M2M authenticates with Databricks\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands.tools.mcp import MCPClient\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Load gateway configuration\n",
    "with open(\"gateway_config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "gw_client = GatewayClient(region_name=config[\"region\"])\n",
    "\n",
    "\n",
    "def _get_tools():\n",
    "    \"\"\"Get MCP tools from the gateway.\"\"\"\n",
    "    token = gw_client.get_access_token_for_cognito(config[\"client_info\"])\n",
    "    mcp = MCPClient(\n",
    "        lambda: streamablehttp_client(\n",
    "            config[\"gateway_url\"],\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "        )\n",
    "    )\n",
    "    mcp.start()\n",
    "    return mcp, mcp.list_tools_sync()\n",
    "\n",
    "\n",
    "# Initialize MCP client and tools at startup\n",
    "mcp_client, tools = _get_tools()\n",
    "print(f\"Loaded {len(tools)} tools from gateway\")\n",
    "\n",
    "\n",
    "@app.entrypoint\n",
    "def invoke(payload, context):\n",
    "    \"\"\"AgentCore Runtime entrypoint.\"\"\"\n",
    "    agent = Agent(\n",
    "        model=BedrockModel(model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\"),\n",
    "        tools=tools,\n",
    "        system_prompt=\"You query Databricks SQL via Unity Catalog. Be concise and return results in a readable format.\",\n",
    "    )\n",
    "    prompt = payload.get(\"prompt\", \"List available catalogs.\")\n",
    "    result = agent(prompt)\n",
    "    return {\"response\": result.message.get(\"content\", [{}])[0].get(\"text\", str(result))}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "runtime-reqs-header",
   "metadata": {},
   "source": [
    "### Create the Requirements File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-reqs-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "strands-agents\n",
    "strands-agents-tools\n",
    "bedrock-agentcore\n",
    "bedrock-agentcore-starter-toolkit\n",
    "mcp\n",
    "boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "runtime-deploy-instructions",
   "metadata": {},
   "source": [
    "### Configure and Deploy with the AgentCore CLI\n",
    "\n",
    "Use the AgentCore starter toolkit CLI to configure and deploy the agent. The CLI handles container image building, ECR push, IAM role creation, and runtime deployment.\n",
    "\n",
    "Run the following commands in your terminal (not in the notebook):\n",
    "\n",
    "```bash\n",
    "# Configure the agent — press Enter to auto-create roles and ECR repo\n",
    "agentcore configure -e databricks_agent.py\n",
    "\n",
    "# Deploy to AgentCore Runtime\n",
    "agentcore deploy\n",
    "```\n",
    "\n",
    "The deployment takes a few minutes. Once complete, you'll see the agent's ARN in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "runtime-status-header",
   "metadata": {},
   "source": [
    "### Check Deployment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "runtime-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also check status programmatically\n",
    "import subprocess\n",
    "result = subprocess.run(['agentcore', 'status'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "screenshot-status",
   "metadata": {},
   "source": [
    "`[SCREENSHOT PLACEHOLDER: agentcore-status-output.png — Output of agentcore status showing the deployed agent details]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "runtime-test-header",
   "metadata": {},
   "source": [
    "### Test the Deployed Agent\n",
    "\n",
    "Once deployed, invoke the agent using the AgentCore CLI or the boto3 SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "runtime-test-cli",
   "metadata": {},
   "source": [
    "#### Option A: Test with the AgentCore CLI\n",
    "\n",
    "```bash\n",
    "agentcore invoke '{\"prompt\": \"List all available catalogs in this Databricks workspace.\"}'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "runtime-test-boto3-header",
   "metadata": {},
   "source": [
    "#### Option B: Test with boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "runtime-test-boto3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Read the agent ARN from the AgentCore config\n",
    "import yaml\n",
    "with open('.bedrock_agentcore.yaml') as f:\n",
    "    ac_config = yaml.safe_load(f)\n",
    "agent_arn = ac_config.get('agent_runtime_arn', '')\n",
    "\n",
    "if agent_arn:\n",
    "    runtime_client = boto3.client('bedrock-agentcore', region_name=REGION)\n",
    "    response = runtime_client.invoke_agent_runtime(\n",
    "        agentRuntimeArn=agent_arn,\n",
    "        runtimeSessionId=\"databricks-test-session-123456789012345\",  # Must be 33+ chars\n",
    "        payload=json.dumps({\"prompt\": \"List all available catalogs.\"}).encode(),\n",
    "        qualifier=\"DEFAULT\",\n",
    "    )\n",
    "    response_body = response['response'].read()\n",
    "    response_data = json.loads(response_body)\n",
    "    print(\"Agent Response:\", json.dumps(response_data, indent=2))\n",
    "else:\n",
    "    print('Agent ARN not found. Run agentcore deploy first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "screenshot-runtime-query",
   "metadata": {},
   "source": [
    "`[SCREENSHOT PLACEHOLDER: runtime-query-output.png — Agent response from AgentCore Runtime showing Databricks query results]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook we learned how to:\n",
    "- Set up a Databricks service principal with OAuth credentials for M2M authentication\n",
    "- Create an Amazon Bedrock AgentCore Gateway with Cognito-based inbound auth (or reuse an existing one)\n",
    "- Configure an OAuth2 credential provider via AgentCore Identity for outbound Databricks auth\n",
    "- Register the Databricks SQL MCP server as a gateway target and synchronize tools\n",
    "- Test the agent locally with a Strands Agent\n",
    "- Deploy the agent to AgentCore Runtime for production use\n",
    "\n",
    "The gateway handles all authentication complexity — your agent code only needs a bearer token to access any tools exposed through the gateway. AgentCore Runtime provides secure, serverless hosting with automatic scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-header",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Run the cells below to delete all resources created in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-runtime",
   "metadata": {},
   "source": [
    "#### Destroy the AgentCore Runtime deployment\n",
    "\n",
    "```bash\n",
    "agentcore destroy\n",
    "```\n",
    "\n",
    "This removes the runtime endpoint, ECR repository, and IAM roles created by the CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-target-header",
   "metadata": {},
   "source": [
    "#### Delete the gateway target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore.delete_gateway_target(gatewayIdentifier=gateway_id, targetId=target_id)\n",
    "print(f\"Deleted target: {target_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-gw-header",
   "metadata": {},
   "source": [
    "#### Delete the gateway and Cognito resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cleanup_gateway(gateway_id, config[\"client_info\"])\n",
    "print(f\"Deleted gateway: {gateway_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-cred-header",
   "metadata": {},
   "source": [
    "#### Delete the OAuth credential provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-cred",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    agentcore.delete_oauth2_credential_provider(name=\"databricks-dbsql-oauth\")\n",
    "    print(\"Deleted OAuth credential provider.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not delete credential provider: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-iam-header",
   "metadata": {},
   "source": [
    "#### Clean up the inline IAM policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-iam",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    gateway_details = agentcore.get_gateway(gatewayIdentifier=gateway_id)\n",
    "    role_name = gateway_details['roleArn'].split('/')[-1]\n",
    "    iam_client = boto3.client('iam')\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyName=\"DatabricksOAuthAccess\",\n",
    "    )\n",
    "    print(f\"Deleted inline policy from role: {role_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not delete inline policy: {e}\")\n",
    "\n",
    "print(\"Cleanup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-files-header",
   "metadata": {},
   "source": [
    "#### Remove generated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for f in ['databricks_agent.py', 'requirements.txt', 'gateway_config.json', '.bedrock_agentcore.yaml']:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f'Removed {f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
